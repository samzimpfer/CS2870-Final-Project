---
title: "Analyzing UFO Sightings"
author: "Shealagh Brown & Sam Zimpfer"
date: "2025-05-01"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
 pacman::p_load(gapminder, socviz, tidyverse, grid, ggthemes,
               usmap, maps, statebins, viridis, leaflet, lubridate, broom, GGally, rpart, rpart.plot, FNN, class, caret) 
```

## Introduction
  The data we were working with came from a data set called "UFO sightings scrubbed" that was found on Kaggle.com from a user named Akhil Goyal. The data was last updated three months ago, making it quite recent data. It contains information on all UFO sightings dating back to 1906. The data could have some bias if ufo sightings from certain regions of the world were not recorded or included in this data set, additionally it is observational data collected by different people around the globe which can create large amounts of variation in the data. \
  This data is of interest because UFOs have been a topic of public debate for years. With increasing amounts of interest in space travel and extraterrestrials in more recent years, the fascinations with UFOs has only grown stronger. For this project we want to explore what influences sightings as this can be valuable knowledge for those trying to investigate UFOs. \
  In order to work with our data we had to clean it. This included converting the datetime column into year, month, day, seconds, minutes, hours format. Then we created a new data set where we added columns for years, seconds, and months and kept the updated datetime, city, state, country, longitude, and latitude columns. We then had to convert both longitude and latitude into numeric values in order to work with them. The code for this data cleaning follows:


```{r clean data}
ufo_raw <- read.csv("ufo_sightings_scrubbed.csv")

#convert date time to ymd_hms format
ufo_raw$datetime <- ymd_hms(ufo_raw$datetime)

#cleaning data
ufo_raw|>
   mutate(seconds = duration..seconds.,
          year = year(datetime), #create year column
          month = month.name[month(datetime)])|> #create month column and convert to name  
  select(datetime, city, state, country, seconds,latitude,longitude, year, month)|>
    filter(seconds <= 40000) |> 
    # filter out badly formatted entries that could cause NA's during the following conversion
    filter(grepl("^[-]?[0-9.]+$", latitude),
           grepl("^[-]?[0-9.]+$", seconds)) -> ufo

  
ufo$latitude <- as.numeric(ufo$latitude) #changing lat to numeric
ufo$seconds <- as.numeric(ufo$seconds) #changing seconds to numeric

ufo <- ufo |> drop_na(longitude, latitude, seconds)

```

## Data Analysis 

The first question we had about UFO sightings is how the location around the world influenced the number of UFO sightings that occurred. We began by creating histograms for longitude and latitude. From there we created a scatter plot to compare latitude and longitude to see if there was a relationship between the two of them. 

```{r, echo = FALSE}
long_hist <- ggplot(
  data = ufo,
  mapping = aes( x= longitude
  )
)+
  geom_histogram(fill = "olivedrab", 
                 color = "black", 
                 bins = 40)+
  labs(
    title = "Number of sightings per longitude",
    x = "Longitude",
    y = "Number of Sightings"
  )+
  scale_x_continuous(breaks = seq(-200, 200, 20))+
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

lat_hist <- ggplot(
  data = ufo,
  mapping = aes( x= latitude
  )
)+
  geom_histogram(fill = "olivedrab", 
                 color = "black",
                 bins = 40)+
  labs(
    title = "Number of sightings per lattitude",
    x = "Latitude",
    y = "Number of Sightings"
  )+
  scale_x_continuous(breaks = seq(-100, 100, 20))+
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

```

```{r, echo = FALSE}
long_hist
```
When looking at the histogram of longitude, we notice there are two main peaks within the spread. One peak is around -120 and the seconds is around -80. This make sense because these are the longitudes that correspond with highly populated areas of the US. The relative height of these peaks implies that there are considerably more sightings in the US than anywhere else in the world. This observation can be interpreted in multiple ways, either that UFO's are more commonly reported in the US than anywhere else (either accurately or inaccurately), or that there really are more UFO visits in the US than anywhere else. We can't make a solid determination between these two based on the data, but we can clearly see that there have been more reports around the US.

```{r, echo = FALSE}
lat_hist
```
In the latitude histogram, we see than sightings are most prevalent around 40. Again, this corresponds to the coordinates of the US and also Europe, which is the second most frequently reported area of UFO sightings. This data supports the same conclusions we see from the longitude histogram.


```{r , echo=FALSE,  map }
map <- map_data("world")

map_plot <- ggplot()+
  geom_polygon(data = map,
               mapping = aes(x= long,
                             y = lat,
                             group = group),
               fill = "darkgreen")+
  geom_point(data = filter(ufo, seconds < 40000),
             mapping = aes(x = longitude,
                           y = latitude,
                           color = seconds),
             size = 0.3
           )+
  labs(
    x = "Longitude",
    y = "Latitude"
  )+
scale_y_continuous(expand = c(0, 0, 0.05, 0))+
  ylim(-60,90)

map_plot
```
Here, we can see in greater detail the geographical dispersion of the sightings. The graph supports the same claims as the previous two graphs. We can also see from the color coding based on duration that most of the sightings are pretty short.


The next question we had was how the number of sightings had increase or decreased over the full epoch of time that the data set spans. We created a histogram of sightings per group of 5 years to answer this question. 

```{r , echo=FALSE,  bargraph }
ggplot( data = ufo,
        mapping = aes(x = year))+
  geom_histogram(fill = "hotpink",
                 color = "black",
                 bins = 20)+
  labs(
    x = "Year",
    y = "Number of Sightings"
  )+
scale_y_continuous(expand = c(0, 0, 0.05, 0))
```
The histogram shows that UFO sightings were relatively infrequent in the early 1900's. Sightings gradually started to increase during the 1950's and then there was a sharp increase at the end of the 1990's and into the 2000's. The number of sightings seems to start to plateau past 2005 also, so it would interesting to see whether the data plateaus in the long term after this point or if it would continue to increase beyond a certain point. This pattern might indicate developments in human history that could be of interest to extraterrestrial beings or have sparked human interest in the existance of extraterrestrials.


```{r , echo=FALSE,  smallmultiples }
# create table of year, month, number of sightings
summary <- ufo |> filter(year >= 2000) |> group_by(year, month) |> summarise(count = n())

# order data by natural month ordering
summary$month <- factor(summary$month, levels = month.name)
summary <- summary |> arrange(year, month)

ggplot(data = summary,
       mapping = aes(x = month,
                     y = count,
                     group = 1)) +
  geom_line() +
  labs(x = "Month",
       y = "Number of Sightings") +
  scale_y_continuous(expand = c(0, 0, 0.05, 0)) +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(~ year)
```
Here we have a small multiples graph which shows the seasonal trends in UFO data since the year 2000. Like the previous graph, these graphs also show that total UFO sightings have increased since 2000. Before 2009 sightings are generally consistent over the years. In 2009 we can see the first real peak during the summer. This trend seems to be reflected in the following years since then. It's possible that this is simply because more people are outdoors at this time of year, so more UFO visits are reported as sightings. Because of this highly plausible explanation, we can't necessarily determine from the data whether there was an actual increase in UFO visits in the summers. 


## Machine learning

###Linear Regression

We wanted to use machine learning techniques to predict the duration of sightings and the longitude/latitude they took place at. We first chose to try to create a linear regression model. We thought this would be appropriate as we wanted to explore how our explanatory variables could explain the duration of sightings which is a numerical response variable. We also thought this would be a good technique to use as it is an eager learner and we wanted to create a model.


```{r , echo=FALSE,  linreg }
lat_lm<- lm(
  formula = seconds ~ latitude,
  data = ufo 
)
  
long_lm<- lm(
  formula = seconds ~ longitude,
  data = ufo 
)
  
lat_long_lm<- lm(
  formula = seconds ~ latitude + longitude,
  data = ufo 
)

bind_rows(
  glance(lat_lm),
  glance(long_lm),
  glance(lat_long_lm)
  ) |> 

  mutate(
    explanatories = c(as.character(formula(lat_lm))[3],
                      as.character(formula(long_lm))[3],
                      as.character(formula(lat_long_lm))[3])
  ) |> 
select(explanatories, r.squared, adj.r.squared, sigma)  


```

#### Residual Plots for Duration of Sightings vs Longitude and Lattitude
```{r , echo=FALSE,  resid }
resid_plot_print <- function(model, title) {
  augment_columns(
  x = model, 
  data = ufo
) |> 
  
  ggplot(
    mapping = aes(
      x = .fitted,
      y = .resid
    )
  ) + 
  
  geom_point(alpha = 0.5) + 
  
  geom_hline(
    yintercept = 0,
    color = "red",
    linewidth = 1
  ) + 
  
  labs(
    x = "Predicted Values",
    y = "Residuals",
    title = paste("Residual Plot for" , title , "Model"
  )) }

resid_plot_print(lat_lm, "Latitude")
resid_plot_print(long_lm, "Longitude" )
resid_plot_print(lat_long_lm, "Longitude and Latitude" )

```

We created three different linear regression models, one with longitude as the explanatory variable, one with latitude as the explanatory variable, adn the third with both. We wanted to compare which model would be the most accurate. From the table above we can see that all three models had R-squared values that were very close to zero. This indicates that our models were not a good predictor of duration of UFO sightings. \

We then made residual graphs to see what else we could notice about our models and the data. These plots also indicate that the linear model is not a good predictor of duration based on longitude or latitude. In each plot there are clusters of outliers that are significantly higher than the majority of the data. 

### kNN regression 
Since our linear regression proved to not be effective in predicting duration of sightings based on longitude or latitude we decided to try a k Nearest Neighbors regression. We noticed that a large portion of the data was acting differently than the rest, and thought kNN regression could account for this. 

``` {r , echo=FALSE,  kNNreg }
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

standardize <- function(x) {
  return((x - mean(x)) / sd(x))
}

ufo_norm <- 
  ufo |> 
  select(longitude, latitude, seconds) |> 
  mutate(
    across(
      .cols = latitude:longitude,
      .fns = normalize
    )
  )

ufo_stan <- 
  ufo |> 
  select(longitude, latitude, seconds) |> 
  mutate(
    across(
      .cols = latitude:longitude,
      .fns = standardize
    )
  )


k <- 1:10


# try with normalizing
fit_stats_norm <- 
  data.frame(k = k,
         R2 = rep(-1, length(k)),
         MAE = rep(-1, length(k)))

for (i in 1:length(k)) {
  norm_knn <- 
    knn.reg(
      train = ufo_norm,
      y = ufo$seconds,
      k = k[i]
    )
  
  fit_stats_norm[i, "R2"] <- norm_knn$R2Pred
  fit_stats_norm[i, "MAE"] <- (ufo$seconds - norm_knn$pred) |> abs() |> mean()
}


fit_stats_norm |> 
  pivot_longer(
    cols = R2:MAE,
    names_to = "fit_stat",
    values_to = "fit"
  ) |> 
  
  ggplot(mapping = aes(x = k,
                       y = fit,
                       color = fit_stat)) + 
  geom_line(show.legend = F) + 
  facet_wrap(facets = ~ fit_stat,
             scales = "free_y",
             ncol = 1)+
  labs(title = "Fit Statistics for Normalized data")


# try with standardizing
fit_stats_stan <- 
  data.frame(k = k,
         R2 = rep(-1, length(k)),
         MAE = rep(-1, length(k)))

for (i in 1:length(k)) {
  stan_knn <- 
    knn.reg(
      train = ufo_stan,
      y = ufo$seconds,
      k = k[i]
    )
  
  fit_stats_stan[i, "R2"] <- stan_knn$R2Pred
  fit_stats_stan[i, "MAE"] <- (ufo$seconds - stan_knn$pred) |> abs() |> mean()
}



fit_stats_stan |> 
  pivot_longer(
    cols = R2:MAE,
    names_to = "fit_stat",
    values_to = "fit"
  ) |> 
  
  ggplot(mapping = aes(x = k,
                       y = fit,
                       color = fit_stat)) + 
  geom_line(show.legend = F) + 
  facet_wrap(facets = ~ fit_stat,
             scales = "free_y",
             ncol = 1)+
  labs(title = "Fit Statistics for Standardized data")

fit_stats_combined <- 
  bind_rows("stan" = fit_stats_stan,
            "norm" = fit_stats_norm,
            .id = "rescale")

fit_stats_combined |>
  filter(
    R2 == max(R2) | MAE == min(MAE)
    
  )



norm_knn <-
  knn.reg(
    train = ufo_norm,
    y = ufo$seconds,
    k = 1
  )

```
When looking at the fit statistic plots for both the normalized and standardized we can see the R-squared values are at their max and the MAE is minimized at values close to one. We then searched the data to find the best k value, which ended up being a k value of one when using the normalized data. This k value is unusual and leads up to believe that this model is likely overfit to the data that we used to train it. \

Both the linear regression and kNN regression failed to be good techniques for the effect of longitude and latitude on duration. This could be due to a lack of relationship between these variables. There is a large portion of the data where the sightings have a very short duration. There is also a second portion of the data that has much longer duration. Additionally, the many sightings are concentrated in the United States and Europe. These nuances of the data could have influenced their behaviors with regression. 

### kNN Classifications

We were also interested in using machine learning to see if we could use latitude and longitude to predict which month a sighting happened in. We started by using kNN classification because our response variable is categorical and we thought it would be an effective method of predicting month based on longitude and latitude.

``` {r , echo=FALSE,  kNNclass }
knn_classification <- 
  knn(
    train = ufo_norm |> select(latitude:longitude),
    test = ufo_norm |> select(latitude:longitude),
    cl = ufo$month,
    k = 12
  )

table(actual = ufo$month,
      predicted = knn_classification)|>
  confusionMatrix(positive = "F")


```
From the confusion matrix displayed above we see that the accuracy of this model is 22.5 %. While this is a relatively low accuracy it is still a 2.1% higher accuracy rate than if predictions were made based on no information. The matrix also shows that this difference is statisitcally signficant, with a p value of  2.2e-16. So while the model isn't super accurate its still better than if there was no information to base preditions on. 

###  Classification Tree

The accuracy of our kNN classification was relatively low so we decided to make a classification tree to make a model of longitude, latitude, and the month of a sighting. We thought this may work better as it is a very large data set and classification trees are able to run quicker. Additonally it would provide a visualization and steps to take when determining the month of a sighting. 
``` {r , echo=FALSE,  Classtree}


# Build the full decision tree here
tree_full<-
  rpart(
    formula = month ~ longitude + latitude,
    data = ufo,
    method = "class",
    parms = list(split = "information"),
    minsplit = 2,
    minbucket = 1,
    cp = -1
  )

#finding xerror cut off
tree_full$cptable |>
  data.frame()|>
  slice_min(xerror, n = 1)|> #finding row with smallest xerror
  mutate(xcutoff = xerror + xstd) |>#calculate cut off value
  pull(xcutoff) ->xcutoff
  

#use xcutoff to find corresponding cp value 
tree_full$cptable|>
  data.frame()|>
  filter(xerror < xcutoff)|> #keeping rows with x error less than x cut off
  slice(1)|>
  pull(CP) -> cp_cutoff

# Prune the tree
prune(tree = tree_full,
      cp = cp_cutoff) -> pruned_tree

# Then plot it:
rpart.plot(
  x = pruned_tree,
  type = 5,
  extra = 102
)

rpart.rules(
  x=pruned_tree,
  extra = 4
)

pruned_tree$cptabl

varImp(object = pruned_tree)

```
The pruned classification tree is displayed above. This tree has a total of 24 nodes. When we look at the CP table for the pruned tree we can see that the xerror 

