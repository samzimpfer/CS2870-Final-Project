---
title: "UFO"
author: "Shealagh Brown & Sam Zimpfer"
date: "2025-03-20"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(gapminder, socviz, tidyverse, grid, ggthemes,
               usmap, maps, statebins, viridis, leaflet, lubridate, broom, GGally, rpart, rpart.plot, FNN, class, caret) 
theme_bw()
```

---


## Cleaning the data

The code chunk below reads in our data about UFO sightings. We had to convert the datetime variable to year, month, date format. Then we created a new data frame containing only necessary variables for our purposes. Latitude had to then be convered into a numeric variable.

The variables used are:
**datetime**: the date and time of sighting in year, month, day, hours, minutes, seconds format. \
**city**: city where sighitng occurred \
**state**: state where sighting occurred \
**country**: country where sighting occurred \
**seconds**: duration of sightings in seconds \
**latitude**: latitude of sighting \
**longitude**: longitude of sighing \
**year**: year when sighing occurred \
**month**: month when sighting occured \

```{r clean data}
ufo_raw <- read.csv("ufo_sightings_scrubbed.csv")

#convert date time to ymd_hms format
ufo_raw$datetime <- ymd_hms(ufo_raw$datetime)

#cleaning data
ufo_raw|>
  # keep duration in seconds form only
   mutate(seconds = duration..seconds.,
          # split datetime data into a year and a month column
          year = year(datetime),
          month = month.name[month(datetime)])|>
  # select relevant columns
  select(datetime, city, state, country, seconds,latitude,longitude, year, month)|>
    filter(seconds <= 40000) |> 
    # filter out badly formatted entries that could cause NA's during the following conversion
    filter(grepl("^[-]?[0-9.]+$", latitude),
           grepl("^[-]?[0-9.]+$", seconds)) -> ufo

  
ufo$latitude <- as.numeric(ufo$latitude) #changing lat to numeric
ufo$seconds <- as.numeric(ufo$seconds) #changing seconds to numeric

# drop any remaining NA entries
ufo <- ufo |> drop_na(longitude, latitude, seconds)

```

---


# Data Summary

The first question we wanted to answer is where do most UFO sightings occur. 

We created histograms of sightings based on longitude and latitude.
```{r pressure, longitude & latitude }
# histogram for longitude
long_hist <- ggplot(
  data = ufo,
  mapping = aes( x= longitude
  )
)+
  geom_histogram(fill = "olivedrab", 
                 color = "black", 
                 bins = 40)+
  labs(
    title = "Number of sightings per longitude",
    x = "Longitude",
    y = "Number of Sightings"
  )+
  scale_x_continuous(breaks = seq(-200, 200, 20))+
  scale_y_continuous(expand = c(0, 0, 0.05, 0))


# histogram for latitude
lat_hist <- ggplot(
  data = ufo,
  mapping = aes( x= latitude
  )
)+
  geom_histogram(fill = "olivedrab", 
                 color = "black",
                 bins = 40)+
  labs(
    title = "Number of sightings per lattitude",
    x = "Latitude",
    y = "Number of Sightings"
  )+
  scale_x_continuous(breaks = seq(-100, 100, 20))+
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

long_hist
lat_hist
```

---


Next, we overlayed the coordinates of the sightings on a map of the world to better visualize.
```{r , map }
map <- map_data("world")

map_plot <- ggplot()+
  geom_polygon(data = map,
               mapping = aes(x= long,
                             y = lat,
                             group = group),
               fill = "darkgreen")+
  geom_point(data = filter(ufo, seconds < 40000),
             mapping = aes(x = longitude,
                           y = latitude,
                           color = seconds),
             size = 0.3
           )+
  labs(
    x = "Longitude",
    y = "Latitude"
  )+
scale_y_continuous(expand = c(0, 0, 0.05, 0))+
  ylim(-60,90)

map_plot
```

### Observations
From the histograms, we noticed that most ufo sightings are concentrated around -120 through -70 longitude and 30 through 50 latitudes. When longitude and latitude are graphed against each other and over layed with a map of the word we can see that these values correspond with a high volume of sightings in the United States. This graph also indicates other potential hot spots of sightings, specifically Europe and the eastern coast of Australia. 

---


## Bar graph of sightings per year
```{r, bar graph of sightings per year}
ggplot( data = ufo,
        mapping = aes(x = year))+
  geom_histogram(fill = "hotpink",
                 color = "black",
                 bins = 20)+
  labs(
    x = "Year",
    y = "Number of Sightings"
  )+
scale_y_continuous(expand = c(0, 0, 0.05, 0))
```

### Observations
UFO sightings were relatively infrequent in the early 1900's. Sightings gradually started to increase during the 1950's and then there was a sharp increase at the end of the 1990's and into the 2000's. 

---


## Small Multiples Graph of Number of Sightings Per Month Since Year 2000
```{r, small multiples}
# create table of year, month, number of sightings
summary <- ufo |> filter(year >= 2000) |> group_by(year, month) |> summarise(count = n())

# order data by natural month ordering
summary$month <- factor(summary$month, levels = month.name)
summary <- summary |> arrange(year, month)

# create small multiples graph
ggplot(data = summary,
       mapping = aes(x = month,
                     y = count,
                     group = 1)) +
  geom_line() +
  labs(x = "Month",
       y = "Number of Sightings") +
  scale_y_continuous(expand = c(0, 0, 0.05, 0)) +
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(~ year)
```

### Observations
When we compare how sightings per month has changed over time we see that generally the amount of sighitngs has increased. Before 2009 sightinga are generally conisistent over the year. In 2009 we can see the first real peak during the summer. This trend seems to be reflected in the following years since then. 

---


#Machine Learning

We want to conduct linear regression to determine the effect that longitude and latitude have on the durration of sighitngs. Before we create a model we will check for 

---


## Setting up linear regression models
```{r,  models}
# create several models to explain seconds in terms of latitude and/or longitude
lat_lm<- lm(
  formula = seconds ~ latitude,
  data = ufo 
)
  
long_lm<- lm(
  formula = seconds ~ longitude,
  data = ufo 
)
  
lat_long_lm<- lm(
  formula = seconds ~ latitude + longitude,
  data = ufo 
)

# create table to compare performance of the different models
bind_rows(
  glance(lat_lm),
  glance(long_lm),
  glance(lat_long_lm)
  ) |> 

  mutate(
    explanatories = c(as.character(formula(lat_lm))[3],
                      as.character(formula(long_lm))[3],
                      as.character(formula(lat_long_lm))[3])
  ) |> 
select(explanatories, r.squared, adj.r.squared, sigma)  


```

---


## Residual Plots for Duration of Sightings vs Longitude and Lattitude
```{r, residual plots}
# define function to show a residual plot of a specified regression model
resid_plot_print <- function(model, title) {
  augment_columns(
  x = model, 
  data = ufo
) |> 
  
  ggplot(
    mapping = aes(
      x = .fitted,
      y = .resid
    )
  ) + 
  
  geom_point(alpha = 0.5) + 
  
  geom_hline(
    yintercept = 0,
    color = "red",
    linewidth = 1
  ) + 
  
  labs(
    x = "Predicted Values",
    y = "Residuals",
    title = paste("Residual Plot for" , title , "Model"
  )) }

resid_plot_print(lat_lm, "Latitude")
resid_plot_print(long_lm, "Longitude" )
resid_plot_print(lat_long_lm, "Longitude and Latitude" )

```

### Observations

---


## Setting up kNN regression- Finding the best k

``` {r finding the best k}
# normalize and standardizing the data
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}

standardize <- function(x) {
  return((x - mean(x)) / sd(x))
}

ufo_norm <- 
  ufo |> 
  select(longitude, latitude, month) |> 
  mutate(
    across(
      .cols = latitude:longitude,
      .fns = normalize
    )
  )

ufo_stan <- 
  ufo |> 
  select(longitude, latitude, month) |> 
  mutate(
    across(
      .cols = latitude:longitude,
      .fns = standardize
    )
  )


# cycling through options for best k and better method of normalizing or standardizing 
k <- 1:20

# try with normalizing
fit_stats_norm <- 
  tibble(k = k,
         R2 = rep(-1, length(k)),
         MAE = rep(-1, length(k)))

for (i in 1:length(k)) {
  norm_knn <- 
    knn.reg(
      train = ufo_norm,
      y = ufo$month,
      k = k[i]
    )
  
  fit_stats_norm[i, "R2"] <- norm_knn$R2Pred
  fit_stats_norm[i, "MAE"] <- (ufo$month - norm_knn$pred) |> abs() |> mean()
}

fit_stats_norm

fit_stats_norm |> 
  pivot_longer(
    cols = R2:MAE,
    names_to = "fit_stat",
    values_to = "fit"
  ) |> 
  
  ggplot(mapping = aes(x = k,
                       y = fit,
                       color = fit_stat)) + 
  geom_line(show.legend = F) + 
  facet_wrap(facets = ~ fit_stat,
             scales = "free_y",
             ncol = 1)


# try with standardizing
fit_stats_stan <- 
  tibble(k = k,
         R2 = rep(-1, length(k)),
         MAE = rep(-1, length(k)))

for (i in 1:length(k)) {
  stan_knn <- 
    knn.reg(
      train = ufo_stan,
      y = ufo$month,
      k = k[i]
    )
  
  fit_stats_stan[i, "R2"] <- stan_knn$R2Pred
  fit_stats_stan[i, "MAE"] <- (ufo$month - stan_knn$pred) |> abs() |> mean()
}

fit_stats_stan

fit_stats_stan |> 
  pivot_longer(
    cols = R2:MAE,
    names_to = "fit_stat",
    values_to = "fit"
  ) |> 
  
  ggplot(mapping = aes(x = k,
                       y = fit,
                       color = fit_stat)) + 
  geom_line(show.legend = F) + 
  facet_wrap(facets = ~ fit_stat,
             scales = "free_y",
             ncol = 1)


# show a table of results
fit_stats_combined <- 
  bind_rows("stan" = fit_stats_stan,
            "norm" = fit_stats_norm,
            .id = "rescale") 

fit_stats_combined |>
  filter(
    R2 == max(R2) | MAE == min(MAE)
    
  )

norm_knn <-
  knn.reg(
    train = ufo_norm,
    y = ufo$month,
    k = 1
  )

```

### Observations
* The best way to go about kNN regression is to use a normalized data set with a k value of 1. This is true because this gives the highest R^2 value of 0.8 and MAE of 296.486.

---


## Making the kNN classification
``` {r making the kNN classification}
# make the classification
knn_classification <- 
  knn(
    train = ufo_norm |> select(latitude:longitude),
    test = ufo_norm |> select(latitude:longitude),
    cl = ufo$month,
    k = 12
  )

# show a table of the classification
table(actual = ufo$month,
      predicted = knn_classification)|>
  confusionMatrix(positive = "F")


```

``` {r classification tree}
# Build the full decision tree here
tree_full<-
  rpart(
    formula = month ~ longitude + latitude,
    data = ufo,
    method = "class",
    parms = list(split = "information"),
    minsplit = 2,
    minbucket = 1,
    cp = -1
  )

#finding xerror cut off
tree_full$cptable |>
  data.frame()|>
  slice_min(xerror, n = 1)|> #finding row with smallest xerror
  mutate(xcutoff = xerror + xstd) |>#calculate cut off value
  pull(xcutoff) ->xcutoff
  

#use xcutoff to find corresponding cp value 
tree_full$cptable|>
  data.frame()|>
  filter(xerror < xcutoff)|> #keeping rows with x error less than x cut off
  slice(1)|>
  pull(CP) -> cp_cutoff


c("xerror cutoff"= xcutoff,
  "cp prune value" = cp_cutoff)

# Prune the tree
prune(tree = tree_full,
      cp = cp_cutoff) -> pruned_tree

# Then plot it:
rpart.plot(
  x = pruned_tree,
  type = 5,
  extra = 102
)

rpart.rules(
  x=pruned_tree,
  extra = 4
)

varImp(object = pruned_tree)

summary(object = pruned_tree,
        digits = 3)
```


